{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REPORT 1 - Economic considerations of different boosting priority strategies\n",
    "\n",
    "In this notebook we compute the economic burdens of different age-priority boosting strategies, using the `warwickmodel`, built by Universities of Warwick and Lancaster, with population data from 5 countries with very different socio-economic profiles.\n",
    "\n",
    "The effectiveness cost of boosters is quantified in terms of reductions in total amount of years of life lost due to boosyer vaccines deploymnet. We assume an initial boosting campaign in the population, with no subsequent boosters being deployed during the simulation. \n",
    "\n",
    "The infection dynamics are run for:\n",
    " - Dates: **15 Feb 2020** - **25 June 2021**;\n",
    " - Countries of interest: **United Kingdom**, **France**;\n",
    " - Number of boosters deployed: **10%** of the population.\n",
    "\n",
    "*The Warwick model is built by Universities of Warwick and Lancaster.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load necessary libraries\n",
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import epimodels as em\n",
    "import warwickmodel as wm\n",
    "import matplotlib\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt\n",
    "from iteration_utilities import deepflatten"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Setup\n",
    "### Define setup matrices for the WarwickLanc Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate the model\n",
    "total_days =  100\n",
    "regions = ['United Kingdom', 'Canada', 'Brazil', 'South Africa', 'Kenya', 'Philippines', 'Sierra Leone', 'Syria']\n",
    "age_groups = ['0-4', '5-9', '10-14', '15-19', '20-24', '25-29', '30-34', '35-39',\n",
    "              '40-44', '45-49', '50-54', '55-59', '60-64', '65-69', '70-74', '75+']\n",
    "\n",
    "regimes = np.arange(1, 101, 20).tolist()\n",
    "\n",
    "# Add folder path to data file\n",
    "path = os.path.join('../data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in corresponding data files for the countries considered for all 100 regimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Matrices contact\n",
    "matrices_contact = []\n",
    "matrices_region = []\n",
    "time_changes_contact = []\n",
    "time_changes_region = []\n",
    "\n",
    "# Vaccine effects\n",
    "nu_tra = []\n",
    "nu_symp = []\n",
    "nu_inf = []\n",
    "nu_sev_h = []\n",
    "nu_sev_d = []\n",
    "\n",
    "# Parameters\n",
    "omega = []\n",
    "alpha = []\n",
    "gamma = []\n",
    "tau = []\n",
    "we = []\n",
    "\n",
    "# Initial conditions\n",
    "susceptibles_IC = []\n",
    "exposed1_IC = []\n",
    "exposed2_IC = []\n",
    "exposed3_IC = []\n",
    "exposed4_IC = []\n",
    "exposed5_IC = []\n",
    "infectives_sym_IC = []\n",
    "infectives_asym_IC = []\n",
    "recovered_IC = []\n",
    "\n",
    "# Risk factors\n",
    "d = []\n",
    "beta = []\n",
    "\n",
    "# Probabilities of proceeding to severe outcomes\n",
    "pItoH = []\n",
    "pHtoD = []\n",
    "\n",
    "# Distribution of delays before proceeding to severe outcomes\n",
    "dItoH = []\n",
    "dHtoD = []\n",
    "\n",
    "for R in regimes:\n",
    "        regimes_matrices_region = []\n",
    "\n",
    "        # Initial state of the system\n",
    "        weeks_matrices_region = []\n",
    "        for r in regions:\n",
    "                region_data_matrix = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Contacts_{}.csv'.format(r, R)),\n",
    "                        header=None, dtype=np.float64)\n",
    "                regional = em.RegionMatrix(r, age_groups, region_data_matrix)\n",
    "                weeks_matrices_region.append(regional)\n",
    "\n",
    "        regimes_matrices_region.append(weeks_matrices_region)\n",
    "\n",
    "        contacts = em.ContactMatrix(age_groups, np.ones((len(age_groups), len(age_groups))))\n",
    "        regimes_matrices_contact = [contacts]\n",
    "\n",
    "        matrices_region.append(regimes_matrices_region)\n",
    "        matrices_contact.append(regimes_matrices_contact)\n",
    "\n",
    "        # Matrices contact\n",
    "        time_changes_contact.append([1])\n",
    "        time_changes_region.append([1])\n",
    "\n",
    "        # Over 75 population fractions\n",
    "        frac_pop_over75 = []\n",
    "\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        skiprows=15,\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                frac_pop_over75.append((1/np.sum(np.asarray(IC_df))) * np.sum(np.asarray(IC_df),axis=1))\n",
    "\n",
    "        # Risk Factors\n",
    "        extended_regimes_d = []\n",
    "        regimes_d = []\n",
    "        regimes_beta = []\n",
    "\n",
    "        for r, reg in enumerate(regions):\n",
    "                RF_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Risks_{}.csv'.format(reg, R)),\n",
    "                        dtype=np.float64)\n",
    "                extended_d = RF_df['symptom_risk'].tolist()\n",
    "                extended_beta = RF_df['susceptibility'].tolist()\n",
    "\n",
    "                extended_regimes_d.append(extended_d)\n",
    "\n",
    "                regimes_d.append(extended_d[:15] + [np.sum(np.multiply(extended_d[15:], frac_pop_over75[r]))])\n",
    "                regimes_beta.append(extended_beta[:15] + [np.sum(np.multiply(extended_beta[15:], frac_pop_over75[r]))])\n",
    "\n",
    "        d.append(regimes_d)\n",
    "        beta.append(regimes_beta)\n",
    "\n",
    "        # Vaccine effects\n",
    "        eff_df = pd.read_csv(\n",
    "                os.path.join(path, 'global_parameters/efficacies_{}.csv'.format(R)),\n",
    "                usecols=range(1,5), dtype=np.float64)\n",
    "\n",
    "        VE_i = eff_df['Infection_eff']\n",
    "        VE_s = eff_df['Symptom_eff']\n",
    "        VE_h = eff_df['Hosp_eff']\n",
    "        VE_d = eff_df['Death_eff']\n",
    "\n",
    "        VE_d = np.divide(VE_d-VE_h, 1-VE_h)\n",
    "        VE_h = np.divide(VE_h-VE_i, 1-VE_i)\n",
    "        VE_s = np.divide(VE_s-VE_i, 1-VE_i)\n",
    "\n",
    "        regimes_nu_tra = [1] * 6\n",
    "        regimes_nu_symp = np.nan_to_num(1 - VE_s).tolist()\n",
    "        regimes_nu_inf = np.nan_to_num(1 - VE_i).tolist()\n",
    "        regimes_nu_sev_h = np.nan_to_num(1 - VE_h).tolist()\n",
    "        regimes_nu_sev_d = np.nan_to_num(1 - VE_d).tolist()\n",
    "\n",
    "        nu_tra.append(regimes_nu_tra)\n",
    "        nu_symp.append(regimes_nu_symp)\n",
    "        nu_inf.append(regimes_nu_inf)\n",
    "        nu_sev_h.append(regimes_nu_sev_h)\n",
    "        nu_sev_d.append(regimes_nu_sev_d)\n",
    "\n",
    "        # Parameters\n",
    "        param_df = pd.read_csv(\n",
    "                os.path.join(path, 'global_parameters/parameters_{}.csv'.format(R)),\n",
    "                dtype=np.float64)\n",
    "\n",
    "        regimes_omega = param_df['transmission'].tolist()[0]\n",
    "        regimes_alpha = 1\n",
    "        regimes_gamma = param_df['recovery'].tolist()[0]\n",
    "        regimes_tau = param_df['asymptomatic_transmission'].tolist()[0]\n",
    "        regimes_we = [param_df['waning_rate'].tolist()[0]] * 2 + [0]\n",
    "\n",
    "        omega.append(regimes_omega)\n",
    "        alpha.append(regimes_alpha)\n",
    "        gamma.append(regimes_gamma)\n",
    "        tau.append(regimes_tau)\n",
    "        we.append(regimes_we)\n",
    "\n",
    "        # Initial conditions\n",
    "        regimes_susceptibles_IC = []\n",
    "        regimes_exposed1_IC = []\n",
    "        regimes_exposed2_IC = []\n",
    "        regimes_exposed3_IC = []\n",
    "        regimes_exposed4_IC = []\n",
    "        regimes_exposed5_IC = []\n",
    "        regimes_infectives_sym_IC = []\n",
    "        regimes_infectives_asym_IC = []\n",
    "        regimes_recovered_IC = []\n",
    "\n",
    "        # Susceptible\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(0, 5),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_S = np.asarray(IC_df)\n",
    "                under_75_S = extended_S[:15, :]\n",
    "                over_75_S = extended_S[15:, :]\n",
    "                reduced_S = np.vstack((under_75_S, np.sum(over_75_S, axis=0)))\n",
    "                regimes_susceptibles_IC.append(\n",
    "                        reduced_S.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Exposed 1\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(5, 10),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_E1 = np.asarray(IC_df)\n",
    "                under_75_E1 = extended_E1[:15, :]\n",
    "                over_75_E1 = extended_E1[15:, :]\n",
    "                reduced_E1 = np.vstack((under_75_E1, np.sum(over_75_E1, axis=0)))\n",
    "                regimes_exposed1_IC.append(\n",
    "                        reduced_E1.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Exposed 2\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(10, 15),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_E2 = np.asarray(IC_df)\n",
    "                under_75_E2 = extended_E2[:15, :]\n",
    "                over_75_E2 = extended_E2[15:, :]\n",
    "                reduced_E2 = np.vstack((under_75_E2, np.sum(over_75_E2, axis=0)))\n",
    "                regimes_exposed2_IC.append(\n",
    "                        reduced_E2.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Exposed 3\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(15, 20),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_E3 = np.asarray(IC_df)\n",
    "                under_75_E3 = extended_E3[:15, :]\n",
    "                over_75_E3 = extended_E3[15:, :]\n",
    "                reduced_E3 = np.vstack((under_75_E3, np.sum(over_75_E3, axis=0)))\n",
    "                regimes_exposed3_IC.append(\n",
    "                        reduced_E3.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Exposed 4\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(20, 25),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_E4 = np.asarray(IC_df)\n",
    "                under_75_E4 = extended_E4[:15, :]\n",
    "                over_75_E4 = extended_E4[15:, :]\n",
    "                reduced_E4 = np.vstack((under_75_E4, np.sum(over_75_E4, axis=0)))\n",
    "                regimes_exposed4_IC.append(\n",
    "                        reduced_E4.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Exposed 5\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(25, 30),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_E5 = np.asarray(IC_df)\n",
    "                under_75_E5 = extended_E5[:15, :]\n",
    "                over_75_E5 = extended_E5[15:, :]\n",
    "                reduced_E5 = np.vstack((under_75_E5, np.sum(over_75_E5, axis=0)))\n",
    "                regimes_exposed5_IC.append(\n",
    "                        reduced_E5.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Symptomatic & Asymptomatic Infectious\n",
    "        for _, r in enumerate(regions):\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=range(30, 35),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_I = np.zeros_like(np.asarray(IC_df))\n",
    "                extended_I[:, 0] = np.matmul(np.diag(regimes_nu_symp[0] * np.array(extended_regimes_d[_])), np.asarray(IC_df)[:, 0])\n",
    "                extended_I[:, 1] = np.matmul(np.diag(regimes_nu_symp[1] * np.array(extended_regimes_d[_])), np.asarray(IC_df)[:, 1])\n",
    "                extended_I[:, 2] = np.matmul(np.diag(regimes_nu_symp[2] * np.array(extended_regimes_d[_])), np.asarray(IC_df)[:, 2])\n",
    "                extended_I[:, 3] = np.matmul(np.diag(regimes_nu_symp[3] * np.array(extended_regimes_d[_])), np.asarray(IC_df)[:, 3])\n",
    "                extended_I[:, 4] = np.matmul(np.diag(regimes_nu_symp[4] * np.array(extended_regimes_d[_])), np.asarray(IC_df)[:, 4])\n",
    "                under_75_I = extended_I[:15, :]\n",
    "                over_75_I = extended_I[15:, :]\n",
    "                reduced_I = np.vstack((under_75_I, np.sum(over_75_I, axis=0)))\n",
    "                regimes_infectives_sym_IC.append(\n",
    "                        reduced_I.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "                extended_A = np.zeros_like(np.asarray(IC_df))\n",
    "                extended_A[:, 0] = np.matmul(np.diag((1 - regimes_nu_symp[0] * np.array(extended_regimes_d[_]))), np.asarray(IC_df)[:, 0])\n",
    "                extended_A[:, 1] = np.matmul(np.diag((1 - regimes_nu_symp[1] * np.array(extended_regimes_d[_]))), np.asarray(IC_df)[:, 1])\n",
    "                extended_A[:, 2] = np.matmul(np.diag((1 - regimes_nu_symp[2] * np.array(extended_regimes_d[_]))), np.asarray(IC_df)[:, 2])\n",
    "                extended_A[:, 3] = np.matmul(np.diag((1 - regimes_nu_symp[3] * np.array(extended_regimes_d[_]))), np.asarray(IC_df)[:, 3])\n",
    "                extended_A[:, 4] = np.matmul(np.diag((1 - regimes_nu_symp[4] * np.array(extended_regimes_d[_]))), np.asarray(IC_df)[:, 4])\n",
    "                under_75_A = extended_A[:15, :]\n",
    "                over_75_A = extended_A[15:, :]\n",
    "                reduced_A = np.vstack((under_75_A, np.sum(over_75_A, axis=0)))\n",
    "                regimes_infectives_asym_IC.append(\n",
    "                        reduced_A.flatten('F').tolist() + [0] * len(age_groups))\n",
    "\n",
    "        # Recovered\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        usecols=[35],\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                extended_R = np.asarray(IC_df)\n",
    "                under_75_R = extended_R[:15, :]\n",
    "                over_75_R = extended_R[15:, :]\n",
    "                reduced_R = np.vstack((under_75_R, np.sum(over_75_R, axis=0)))\n",
    "                regimes_recovered_IC.append(\n",
    "                        reduced_R.flatten('F').tolist())\n",
    "\n",
    "        susceptibles_IC.append(regimes_susceptibles_IC)\n",
    "        exposed1_IC.append(regimes_exposed1_IC)\n",
    "        exposed2_IC.append(regimes_exposed2_IC)\n",
    "        exposed3_IC.append(regimes_exposed3_IC)\n",
    "        exposed4_IC.append(regimes_exposed4_IC)\n",
    "        exposed5_IC.append(regimes_exposed5_IC)\n",
    "        infectives_sym_IC.append(regimes_infectives_sym_IC)\n",
    "        infectives_asym_IC.append(regimes_infectives_asym_IC)\n",
    "        recovered_IC.append(regimes_recovered_IC)\n",
    "\n",
    "        # Set time-to-hospitalisation using a Gamma distribution using the mean and standard deviation \n",
    "        th_mean = param_df['hosp_lag'].tolist()[0]+0.00001\n",
    "        th_var = 12.1**2\n",
    "        theta = th_var / th_mean\n",
    "        k = th_mean / theta\n",
    "        time_to_hosp = scipy.stats.gamma(k, scale=theta).pdf(np.arange(1, 31)).tolist()\n",
    "\n",
    "        # Set time-to-death using a Gamma distribution using the mean and standard deviation\n",
    "        td_mean = param_df['death_lag'].tolist()[0]\n",
    "        td_var = 12.1**2\n",
    "        theta = td_var / td_mean\n",
    "        k = td_mean / theta\n",
    "        time_to_death = scipy.stats.gamma(k, scale=theta).pdf(np.arange(1, 31)).tolist()\n",
    "\n",
    "        # Probabilities of proceeding to severe outcomes\n",
    "        # Infected -> Hospital\n",
    "        extended_pItoH = RF_df['hospitalisation_risk'].tolist()\n",
    "\n",
    "        regimes_pItoH = []\n",
    "        for r, reg in enumerate(regions):\n",
    "                regimes_pItoH.append(extended_pItoH[:15] + [np.sum(np.multiply(extended_pItoH[15:], frac_pop_over75[r]))])\n",
    "\n",
    "        pItoH.append(regimes_pItoH)\n",
    "\n",
    "        # Hospital -> Death\n",
    "        extended_pHtoD = RF_df['death_risk'].tolist()\n",
    "\n",
    "        regimes_pHtoD = []\n",
    "        for r, reg in enumerate(regions):\n",
    "                regimes_pHtoD.append(extended_pHtoD[:15] + [np.sum(np.multiply(extended_pHtoD[15:], frac_pop_over75[r]))])\n",
    "\n",
    "        pHtoD.append(regimes_pHtoD)\n",
    "\n",
    "        # Distribution of delays before proceeding to severe outcomes\n",
    "        # Infected -> Hospital\n",
    "        dItoH.append(time_to_hosp)\n",
    "        # Hospital -> Death\n",
    "        dHtoD.append(time_to_death)\n",
    "\n",
    "# Other parameters\n",
    "vac=0\n",
    "vacb=0\n",
    "\n",
    "adult = np.ones(len(age_groups))\n",
    "adult[0] = 0\n",
    "adult[1] = 0\n",
    "adult[2] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate life expectancy for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/Life_expectancy_Canada.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 6\u001b[0m\n\u001b[1;32m      2\u001b[0m life_ex \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m r, reg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(regions):\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;66;03m# Read life expectancy data\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m         LE_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLife_expectancy_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                \u001b[49m\u001b[43musecols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat64\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m         LE \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(LE_df)\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Read age & sex distribution data\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1736\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/warwick/lib/python3.10/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    858\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    859\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    860\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    861\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/Life_expectancy_Canada.csv'"
     ]
    }
   ],
   "source": [
    "# Read region-dependent vectors of years of life lost\n",
    "life_ex = []\n",
    "\n",
    "for r, reg in enumerate(regions):\n",
    "        # Read life expectancy data\n",
    "        LE_df = pd.read_csv(os.path.join(path, 'Life_expectancy_{}.csv'.format(reg)),\n",
    "                usecols=[1, 2], dtype=np.float64)\n",
    "        LE = np.array(LE_df)\n",
    "\n",
    "        # Read age & sex distribution data\n",
    "        ASD_df = pd.read_csv(os.path.join(path, 'Age_sex_distribution_{}.csv'.format(reg)),\n",
    "                usecols=[1, 2], dtype=np.float64)\n",
    "        extended_ASD = np.array(ASD_df)\n",
    "        ASD = np.zeros_like(LE)\n",
    "\n",
    "        # Group the ages of the ASD into the same age groups as the LE\n",
    "        sum_ages = [\n",
    "                0, range(1, 5), range(5, 10), range(10, 15), range(15, 20), range(20, 25), range(25, 30), range(30, 35), range(35, 40), \n",
    "                range(40, 45), range(45, 50), range(50, 55), range(55, 60), range(60, 65), range(65, 70), range(70, 75), range(75, 80), \n",
    "                range(80, 85), range(85, 101)]\n",
    "\n",
    "        ASD[0, :] = extended_ASD[sum_ages[0], :]\n",
    "\n",
    "        for _, ages in enumerate(sum_ages[1:]):\n",
    "                ASD[_ + 1, :] = np.sum(extended_ASD[ages, :], axis=0)\n",
    "\n",
    "        frac_ASD = np.matmul(np.diag(1/np.sum(ASD, axis=1)), ASD)\n",
    "\n",
    "        # Compute the life expectancy of the different age groups\n",
    "        total_LE = np.sum(np.multiply(frac_ASD, LE), axis=1)\n",
    "\n",
    "        # Read Life expectancy data\n",
    "        frac_AD = (1/np.sum(ASD[:2, :]) * np.sum(ASD[:2, :], axis=1)).tolist() + [1] * 14 + (1/np.sum(ASD[16:, :]) * np.sum(ASD[16:, :], axis=1)).tolist()\n",
    "\n",
    "        # Compute the life expectancy of the correct age groups\n",
    "        split_LE = np.multiply(frac_AD, total_LE)\n",
    "        \n",
    "        final_LE = np.zeros(len(age_groups))\n",
    "        final_LE[0] = np.sum(split_LE[:2])\n",
    "        final_LE[1:15] = split_LE[2:16]\n",
    "        final_LE[15] = np.sum(split_LE[16:]).tolist()\n",
    "\n",
    "        life_ex.append(final_LE)\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate total population for each regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the number of boosters for each region\n",
    "total_pop = []\n",
    "\n",
    "for R in regimes:\n",
    "        regimes_total_pop = []\n",
    "        for r in regions:\n",
    "                IC_df = pd.read_csv(\n",
    "                        os.path.join(path, '{}/Start_pop_{}.csv'.format(r, R)),\n",
    "                        header=None, dtype=np.float64)\n",
    "\n",
    "                regimes_total_pop.append(np.sum(np.asarray(IC_df)))\n",
    "        total_pop.append(regimes_total_pop)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Boosting campaign scenarios\n",
    "\n",
    "We only boost the partially-waned and recovered. However those in the R compartment who receive the booster do not move out of the compartment (they have higher immunity than the boosted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maximum percentage booster uptake of each age group\n",
    "boost_age_percent = 0.9\n",
    "\n",
    "# Compute the maximum number of boosters we can deploy for each age group in each region\n",
    "max_boosters = []\n",
    "max_boosters_for_R = []\n",
    "max_boosters_for_S = []\n",
    "max_boosters_for_Sf = []\n",
    "max_boosters_for_Sw1 = []\n",
    "max_boosters_for_Sw2 = []\n",
    "max_boosters_for_Sw3 = []\n",
    "\n",
    "for R, _ in enumerate(regimes):\n",
    "        regimes_max_boosters = []\n",
    "        regimes_max_boosters_for_R = []\n",
    "        regimes_max_boosters_for_S = []\n",
    "        regimes_max_boosters_for_Sf = []\n",
    "        regimes_max_boosters_for_Sw1 = []\n",
    "        regimes_max_boosters_for_Sw2 = []\n",
    "        regimes_max_boosters_for_Sw3 = []\n",
    "\n",
    "        for r, reg in enumerate(regions):\n",
    "                boosters_for_R = boost_age_percent * np.asarray(recovered_IC[R][r])\n",
    "                boosters_for_S = boost_age_percent * np.asarray(susceptibles_IC[R][r])[:len(age_groups)]\n",
    "                boosters_for_Sf = boost_age_percent * np.asarray(susceptibles_IC[R][r])[len(age_groups):(2*len(age_groups))]\n",
    "                boosters_for_Sw1 = boost_age_percent * np.asarray(susceptibles_IC[R][r])[(3*len(age_groups)):(4*len(age_groups))]\n",
    "                boosters_for_Sw2 = boost_age_percent * np.asarray(susceptibles_IC[R][r])[(4*len(age_groups)):(5*len(age_groups))]\n",
    "                boosters_for_Sw3 = boost_age_percent * np.asarray(susceptibles_IC[R][r])[(5*len(age_groups)):(6*len(age_groups))]\n",
    "\n",
    "                regimes_max_boosters_for_R.append(boosters_for_R)\n",
    "                regimes_max_boosters_for_S.append(boosters_for_S)\n",
    "                regimes_max_boosters_for_Sf.append(boosters_for_Sf)\n",
    "                regimes_max_boosters_for_Sw1.append(boosters_for_Sw1)\n",
    "                regimes_max_boosters_for_Sw2.append(boosters_for_Sw2)\n",
    "                regimes_max_boosters_for_Sw3.append(boosters_for_Sw3)\n",
    "\n",
    "                regimes_max_boosters.append(\n",
    "                        boosters_for_R + boosters_for_S + boosters_for_Sf +\n",
    "                        boosters_for_Sw1 + boosters_for_Sw2 + boosters_for_Sw3)\n",
    "\n",
    "        max_boosters_for_R.append(regimes_max_boosters_for_R)\n",
    "        max_boosters_for_S.append(regimes_max_boosters_for_S)\n",
    "        max_boosters_for_Sf.append(regimes_max_boosters_for_Sf)\n",
    "        max_boosters_for_Sw1.append(regimes_max_boosters_for_Sw1)\n",
    "        max_boosters_for_Sw2.append(regimes_max_boosters_for_Sw2)\n",
    "        max_boosters_for_Sw3.append(regimes_max_boosters_for_Sw3)\n",
    "        max_boosters.append(regimes_max_boosters)\n",
    "\n",
    "# Create list of new susceptible_ICs for each vaccination scenario\n",
    "scenario_susceptibles_IC = []\n",
    "scenario_boost_pop_percent = []\n",
    "scenario_names = []\n",
    "age_boosting_scenario_order = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 1**: Prioritising those 75+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_names.append('Prioritise 75+')\n",
    "age_boosting_scenario_order.append((np.arange(16, 0, -1) - 1).tolist())\n",
    "scenario_boost_pop_percent.append(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 2**: Prioritising those 60-74 then 75+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_names.append('Prioritise 60-74 then 75+')\n",
    "age_boosting_scenario_order.append([range(12, 15), 15] + (np.arange(12, 0, -1) - 1).tolist())\n",
    "scenario_boost_pop_percent.append(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 3**: Prioritising those 60-74 then 50-59, then 75+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_names.append('Prioritise those 60-74 then 50-59, then 75+')\n",
    "age_boosting_scenario_order.append([range(12, 15), range(10, 12), 15] + (np.arange(10, 0, -1) - 1).tolist())\n",
    "scenario_boost_pop_percent.append(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Scenario 4**: Prioritising those 50-59, then 60-74 then 75+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scenario_names.append('Prioritise those 50-59 then 60-74, then 75+')\n",
    "age_boosting_scenario_order.append([range(10, 12), range(12, 15), 15] + (np.arange(10, 0, -1) - 1).tolist())\n",
    "scenario_boost_pop_percent.append(0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute new susceptible conditions based on each boosting scenario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s, _ in enumerate(scenario_names):\n",
    "    regimes_new_susceptibles_IC = []\n",
    "    scenario_boosters = (scenario_boost_pop_percent[s] * np.array(total_pop)).tolist()\n",
    "\n",
    "    for R, _ in enumerate(regimes):\n",
    "        new_susceptibles_IC = [\n",
    "            np.array(susceptibles_IC[R][r].copy()).reshape((6, 16)).transpose() for r in range(len(regions))]\n",
    "        \n",
    "        new_susceptibles_IC = np.array(new_susceptibles_IC)\n",
    "        regimes_scenario_boosters = scenario_boosters[R]\n",
    "        reg_new_susceptibles_IC = []\n",
    "\n",
    "        for r, reg in enumerate(regions):\n",
    "            for ages in age_boosting_scenario_order[s]:\n",
    "                if np.sum(max_boosters[R][r][ages]) <= scenario_boosters[R][r]:\n",
    "                    # Add boosted from the S, Sf, Sw1, Sw2, Sw3 to Sb\n",
    "                    new_susceptibles_IC[r, ages, 2] += max_boosters[R][r][ages] - max_boosters_for_R[R][r][ages]\n",
    "                    # Remove boosted from the S\n",
    "                    new_susceptibles_IC[r, ages, 0] -= max_boosters_for_S[R][r][ages]\n",
    "                    # Remove boosted from the Sf\n",
    "                    new_susceptibles_IC[r, ages, 1] -= max_boosters_for_Sf[R][r][ages]\n",
    "                    # Remove boosted from the Sw1\n",
    "                    new_susceptibles_IC[r, ages, 3] -= max_boosters_for_Sw1[R][r][ages]\n",
    "                    # Remove boosted from the Sw2\n",
    "                    new_susceptibles_IC[r, ages, 4] -= max_boosters_for_Sw2[R][r][ages]\n",
    "                    # Remove boosted from the Sw3\n",
    "                    new_susceptibles_IC[r, ages, 5] -= max_boosters_for_Sw3[R][r][ages]\n",
    "                    # Remove boosted from the S, Sf, Sw1, Sw2, Sw3 and R from total boosters for the scenario\n",
    "                    scenario_boosters[R][r] -= np.sum(max_boosters[R][r][ages])\n",
    "                else:\n",
    "                    # Compute proportion of boosters we have left to give for the age group\n",
    "                    prop = scenario_boosters[R][r] / np.sum(max_boosters[R][r][ages])\n",
    "                    # Add boosted from the S, Sf, Sw1, Sw2, Sw3 to Sb\n",
    "                    new_susceptibles_IC[r, ages, 2] += prop * (max_boosters[R][r][ages] - max_boosters_for_R[R][r][ages])\n",
    "                    # Remove boosted from the S\n",
    "                    new_susceptibles_IC[r, ages, 0] -= prop * max_boosters_for_S[R][r][ages]\n",
    "                    # Remove boosted from the Sf\n",
    "                    new_susceptibles_IC[r, ages, 1] -= prop * max_boosters_for_Sf[R][r][ages]\n",
    "                    # Remove boosted from the Sw1\n",
    "                    new_susceptibles_IC[r, ages, 3] -= prop * max_boosters_for_Sw1[R][r][ages]\n",
    "                    # Remove boosted from the Sw2\n",
    "                    new_susceptibles_IC[r, ages, 4] -= prop * max_boosters_for_Sw2[R][r][ages]\n",
    "                    # Remove boosted from the Sw3\n",
    "                    new_susceptibles_IC[r, ages, 5] -= prop * max_boosters_for_Sw3[R][r][ages]\n",
    "                    # Remove boosted from the S, Sf, Sw1, Sw2, Sw3 and R from total boosters for the scenario\n",
    "                    scenario_boosters[R][r] -= prop * np.sum(max_boosters[R][r][ages])\n",
    "\n",
    "            reg_new_susceptibles_IC.append(list(deepflatten(new_susceptibles_IC[r].transpose())))\n",
    "\n",
    "        regimes_new_susceptibles_IC.append(reg_new_susceptibles_IC)\n",
    "    scenario_susceptibles_IC.append(regimes_new_susceptibles_IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the parameters and initial conditions of the model and bundle everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model\n",
    "model = wm.WarwickLancSEIRModel()\n",
    "\n",
    "# Set the region names, contact and regional data of the model\n",
    "model.set_regions(regions)\n",
    "model.set_age_groups(age_groups)\n",
    "\n",
    "# List of times at which we wish to evaluate the states of the compartments of the model\n",
    "times = np.arange(1, total_days+1, 1).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulate for the regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate for all the regions and regimes\n",
    "outputs = []\n",
    "total_pop = []\n",
    "\n",
    "for s, scenario in enumerate(scenario_names):\n",
    "    scenario_outputs = []\n",
    "    scenario_total_pop = []\n",
    "    for R, regime in enumerate(regimes):\n",
    "        model.read_contact_data(matrices_contact[R], time_changes_contact[R])\n",
    "        model.read_regional_data(matrices_region[R], time_changes_region[R])\n",
    "\n",
    "        # Set regional and time dependent parameters\n",
    "        regional_parameters = wm.RegParameters(\n",
    "            model=model,\n",
    "            region_index=1\n",
    "        )\n",
    "\n",
    "        # Set ICs parameters\n",
    "        ICs_parameters = wm.ICs(\n",
    "            model=model,\n",
    "            susceptibles_IC=scenario_susceptibles_IC[s][R],\n",
    "            exposed1_IC=exposed1_IC[R],\n",
    "            exposed2_IC=exposed2_IC[R],\n",
    "            exposed3_IC=exposed3_IC[R],\n",
    "            exposed4_IC=exposed4_IC[R],\n",
    "            exposed5_IC=exposed5_IC[R],\n",
    "            infectives_sym_IC=infectives_sym_IC[R],\n",
    "            infectives_asym_IC=infectives_asym_IC[R],\n",
    "            recovered_IC=recovered_IC[R]\n",
    "        )\n",
    "\n",
    "        # Compute age-dependent population\n",
    "        scenario_total_pop.append(ICs_parameters.total_population())\n",
    "\n",
    "        # Set disease-specific parameters\n",
    "        disease_parameters = wm.DiseaseParameters(\n",
    "            model=model,\n",
    "            d=d[R][0],\n",
    "            tau=tau[R],\n",
    "            we=we[R],\n",
    "            omega=omega[R]\n",
    "        )\n",
    "\n",
    "        # Set transmission parameters\n",
    "        transmission_parameters = wm.Transmission(\n",
    "            model=model,\n",
    "            beta=beta[R][0],\n",
    "            alpha=alpha[R],\n",
    "            gamma=gamma[R]\n",
    "        )\n",
    "\n",
    "        # Set other simulation parameters\n",
    "        simulation_parameters = wm.SimParameters(\n",
    "            model=model,\n",
    "            method='Radau',\n",
    "            times=times,\n",
    "            eps=False\n",
    "        )\n",
    "\n",
    "        # Set vaccination parameters\n",
    "        vaccine_parameters = wm.VaccineParameters(\n",
    "            model=model,\n",
    "            vac=vac,\n",
    "            vacb=vacb,\n",
    "            adult=adult,\n",
    "            nu_tra=nu_tra[R],\n",
    "            nu_symp=nu_symp[R],\n",
    "            nu_inf=nu_inf[R],\n",
    "            nu_sev_h=nu_sev_h[R],\n",
    "            nu_sev_d=nu_sev_d[R],\n",
    "        )\n",
    "\n",
    "        # Set social distancing parameters\n",
    "        soc_dist_parameters = wm.SocDistParameters(\n",
    "            model=model,\n",
    "            phi=1\n",
    "        )\n",
    "\n",
    "        # Set all parameters in the controller\n",
    "        parameters = wm.ParametersController(\n",
    "            model=model,\n",
    "            regional_parameters=regional_parameters,\n",
    "            ICs_parameters=ICs_parameters,\n",
    "            disease_parameters=disease_parameters,\n",
    "            transmission_parameters=transmission_parameters,\n",
    "            simulation_parameters=simulation_parameters,\n",
    "            vaccine_parameters=vaccine_parameters,\n",
    "            soc_dist_parameters=soc_dist_parameters\n",
    "        )\n",
    "\n",
    "        # Simulate for all the regions\n",
    "        regimes_outputs = []\n",
    "        for r, reg in enumerate(regions):\n",
    "            # List of initial conditions and parameters that characterise the model\n",
    "            parameters.regional_parameters.region_index = r + 1\n",
    "\n",
    "            parameters.disease_parameters.d = d[R][r]\n",
    "            parameters.transmission_parameters.beta = beta[R][r]\n",
    "\n",
    "            # Simulate using the ODE solver\n",
    "            regimes_outputs.append(model.simulate(parameters))\n",
    "\n",
    "        scenario_outputs.append(regimes_outputs)\n",
    "\n",
    "    outputs.append(scenario_outputs)\n",
    "    total_pop.append(scenario_total_pop)\n",
    "\n",
    "outputs = np.array(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot the comparments of the two methods against each other\n",
    "### Setup ``plotly`` and default settings for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "colours = ['blue', 'green', 'purple', 'pink', 'black', 'gray', 'red', 'orange']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of New Infections, Hospitalisations, Deaths & Total number of years of life lost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate for all the regions (sum over all age groups)\n",
    "total_years_of_life_lost = []\n",
    "\n",
    "for s, scenario in enumerate(scenario_names):\n",
    "    scenario_total_years_of_life_lost = []\n",
    "    for R, regime in enumerate(regimes):\n",
    "        regimes_total_years_of_life_lost = []\n",
    "        for r, reg in enumerate(regions):\n",
    "            # Compute regional matrix of new infections for all timepoints simulated\n",
    "            reg_new_infections = model.new_infections(outputs[s, R, r, :, :])\n",
    "\n",
    "            # Compute regional matrix of new hospitalisation for all timepoints simulated\n",
    "            reg_new_hospitalisation = model.new_hospitalisations(reg_new_infections, pItoH[R][r], dItoH[R])\n",
    "\n",
    "            # Compute regional matrix of new deaths for all timepoints simulated\n",
    "            reg_years_of_life_lost = model.new_deaths(reg_new_hospitalisation, pHtoD[R][r], dHtoD[R])\n",
    "\n",
    "            regimes_total_years_of_life_lost.append(np.sum((10**5) * np.matmul(np.divide(\n",
    "                reg_new_deaths[0] + reg_new_deaths[1] + reg_new_deaths[2] +\n",
    "                reg_new_deaths[3] + reg_new_deaths[4] + reg_new_deaths[5],\n",
    "                total_pop[s][R][r]), np.diag(life_ex[r])), axis=1))\n",
    "\n",
    "        scenario_total_years_of_life_lost.append(regimes_total_years_of_life_lost)\n",
    "\n",
    "    total_years_of_life_lost.append(scenario_total_years_of_life_lost)\n",
    "\n",
    "total_years_of_life_lost = np.array(total_years_of_life_lost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up traces to plot\n",
    "total_years_of_life_lost_mean = []\n",
    "total_years_of_life_lost_upper = []\n",
    "total_years_of_life_lost_lower = []\n",
    "\n",
    "for r, _ in enumerate(regions):\n",
    "    # Compute the mean \n",
    "    total_years_of_life_lost_mean.append(np.mean(total_years_of_life_lost[:,:,r,:], axis=1))\n",
    "\n",
    "    # Compute the upper quantiles\n",
    "    total_years_of_life_lost_upper.append(np.quantile(total_years_of_life_lost[:,:,r,:], 0.975, axis=1))\n",
    "\n",
    "    # Compute the lower qunatiles\n",
    "    total_years_of_life_lost_lower.append(np.quantile(total_years_of_life_lost[:,:,r,:], 0.025, axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the time series of numbers of years lost of the two regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trace names - represent the solver used for the simulation\n",
    "trace_name = ['region {}'.format(r) for r in regions]\n",
    "\n",
    "# Plot for each boosting scenario\n",
    "for s, scenario in enumerate(scenario_names):\n",
    "    fig = go.Figure()\n",
    "    # Plot (line plot for each solver method for each age)\n",
    "    for r, reg in enumerate(regions):\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                y=total_years_of_life_lost_mean[r][s, :],\n",
    "                x=parameters.simulation_parameters.times,\n",
    "                mode='lines',\n",
    "                name=trace_name[r],\n",
    "                line_color=colours[r],\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.add_trace(\n",
    "            go.Scatter(\n",
    "                y=total_years_of_life_lost_upper[r][s, :].tolist() + total_years_of_life_lost_lower[r][s, :].tolist()[::-1],\n",
    "                x=parameters.simulation_parameters.times + parameters.simulation_parameters.times[::-1],\n",
    "                mode='lines',\n",
    "                name=trace_name[r],\n",
    "                fill='toself',\n",
    "                fillcolor=colours[r],\n",
    "                line_color=colours[r],\n",
    "                opacity=0.15,\n",
    "                showlegend=False\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Add axis labels\n",
    "    fig.update_layout(\n",
    "        boxmode='group',\n",
    "        title='Deaths per 100,000 for Scenario: {}'.format(scenario),\n",
    "        width=800,\n",
    "        height=500,\n",
    "        plot_bgcolor='white',\n",
    "        xaxis=dict(linecolor='black'),\n",
    "        yaxis=dict(linecolor='black'),\n",
    "        hovermode='x unified'\n",
    "        )\n",
    "\n",
    "    fig.write_image('images/Deaths Scenario {}.pdf'.format(s+1))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_colours = ['blue', 'orange', 'green', 'red']\n",
    "\n",
    "fig = go.Figure()\n",
    "# Plot for each region\n",
    "for s, scenario in enumerate(scenario_names):\n",
    "    fig.add_trace(\n",
    "        go.Bar(\n",
    "            y=[np.sum(total_years_of_life_lost_mean[r][s, :]) for r, reg in enumerate(regions)],\n",
    "            x=regions,\n",
    "            name=scenario_names[s],\n",
    "            marker_color=new_colours[s],\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Add axis labels\n",
    "fig.update_layout(\n",
    "    boxmode='group',\n",
    "    title='Deaths per 100,000 for different countries and scenarios',\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    plot_bgcolor='white',\n",
    "    xaxis=dict(linecolor='black'),\n",
    "    yaxis=dict(linecolor='black'),\n",
    "    hovermode='x unified',\n",
    "    legend=dict(\n",
    "            orientation=\"h\",\n",
    "            yanchor=\"bottom\",\n",
    "            y=1.02,\n",
    "            xanchor=\"right\",\n",
    "            x=1\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig.write_image('images/Deaths per Scenario and Country.pdf')\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "68071bb08c320916033ffa6702342928cea5ba8baa6ee7305e5c9ae08c2309c8"
  },
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit ('warwick': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
